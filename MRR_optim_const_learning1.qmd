---
title: "MRR optimization subject to roughness constraint learning 1"
author: "Robson Bruno Dutra Pereira"
format: html
editor: visual
---

## Loading libraries, defining experimental design, and getting measurement results.

The same as done previously.

```{r message = F, echo = F}
library(rsm)
library(MaxPro)
library(dplyr)
library(tidymodels)
library(rules)
library(baguette)
library(finetune)
library(DALEX)
library(DALEXtra)
library(forcats)
library(lhs)
library(Cubist)
library(tidyrules)
library(metaheuristicOpt)
```

```{r message = F, echo = F}

plan <- bbd(3,
            n0 = 2,
            coding = list(x1 ~ (fza - 0.875)/0.375,        # um/dente
                          x2 ~ (fzt - 0.15)/0.05,   # mm/dente
                          x3 ~ (vc - 40)/20),         # m/min
            randomize = F)

plan01 <- plan[,3:5]
plan01$x1 <- (plan$x1 - min(plan$x1))/(max(plan$x1) - min(plan$x1))
plan01$x2 <- (plan$x2 - min(plan$x2))/(max(plan$x2) - min(plan$x2))
plan01$x3 <- (plan$x3 - min(plan$x3))/(max(plan$x3) - min(plan$x3))

set.seed(7)
plan_cand <- CandPoints(N = 6, p_cont = 3, l_disnum=NULL, l_nom=NULL)

plan_rand <- MaxProAugment(as.matrix(plan01), plan_cand, nNew = 6,
                           p_disnum=0, l_disnum=NULL, p_nom=0, l_nom=NULL)
plan_rand2 <- data.frame(plan_rand$Design)
colnames(plan_rand2) <- c("x1","x2", "x3")

plan_rand2$x1 <- plan_rand2$x1*(max(plan$x1) - min(plan$x1)) + min(plan$x1)
plan_rand2$x2 <- plan_rand2$x2*(max(plan$x2) - min(plan$x2)) + min(plan$x2)
plan_rand2$x3 <- plan_rand2$x3*(max(plan$x3) - min(plan$x3)) + min(plan$x3)

plan2 <- data.frame(plan_rand2)
plan2$fza <- plan2$x1*0.375 + 0.875
plan2$fzt <- plan2$x2*0.05 + 0.15
plan2$vc  <- plan2$x3*20 + 40

set.seed(5)
plan2$run.order <- sample(1:nrow(plan2),nrow(plan2),replace=F)

```

```{r message = F, echo = F}
plan_ <- rbind(plan2, plan2)

rough <- c(1.9155556, 3.5155556, 1.0655556, 1.9655556, 1.7655556, 3.2655556, 1.1655556, 2.5655556, 3.1155556, 1.6655556, 3.2655556, 1.3655556, 1.9155556, 2.0155556, 1.9655556, 3.5155556, 0.9655556, 2.5155556, 1.6655556, 2.3155556, 1.6655556, 3.6155556, 0.7655556, 1.9655556, 0.8655556, 2.8155556, 1.0155556, 4.3155556, 2.9155556, 1.4155556, 4.7155556, 1.8655556, 1.8155556, 2.2155556, 1.7655556, 3.4655556, 0.8655556, 2.2155556, 2.3655556, 1.9155556)

plan_ <- plan_ %>%
  mutate(lc = rep(c("emulsion", "mql"), each = 20),
         Ra = rough)

plan_ <- plan_ %>%
  select(fza,fzt,vc,lc,Ra)
head(plan_)
```

```{r message = F, echo = F}
set.seed(1501)
plan_split <- initial_split(plan_, strata = lc)
  
plan_train <- training(plan_split)
plan_test  <- testing(plan_split)

set.seed(1502)
plan_folds <- 
  vfold_cv(v = 5, plan_train, repeats = 2)

```

### Cubist model

```{r}
normalized_rec <- 
  recipe(Ra ~ ., data = plan_train) %>% 
  step_normalize(fza,fzt,vc) %>%
  step_dummy(all_nominal_predictors())

cubist_spec <- 
 cubist_rules(committees = 78, neighbors = 7) %>% 
 set_engine("Cubist")

cubist_wflow <- 
  workflow() %>%
    add_model(cubist_spec) %>%
  add_recipe(normalized_rec)

cubist_final_fit <- fit(cubist_wflow, data = plan_train)
```

```{r}
augment(cubist_final_fit, new_data = plan_test) %>%
  rsq(truth = Ra, estimate = .pred)
```

```{r}
augment(cubist_final_fit, new_data = plan_test) %>%
  rmse(truth = Ra, estimate = .pred)
```

```{r}
cubist_fit <- cubist(x = plan_train[,1:4],
                     y = plan_train$Ra,
                     committees = 78, neighbors = 7)

tidyRules(cubist_fit)
```

### Optimization of material removal rate with Ra contraint learning

First MRR function is defined.

```{r}
MRR <- function(x){

  z <- 2
  Db <- 25
  Dt <- 14
  Dh <- Db-Dt
  
  f1 <- 250*z*(Db^3/(Dh*Dt))*x[3]*((x[1]*10^-3)/x[2])*sqrt((x[1]*10^-3)^2 + (x[2]*Dh/Db)^2)
  
  return(f1)
} 

```

Writing Cubist constraint. Change lc (`"emulsion"` or `"mql"`) as desired.

```{r}
g1 <- function(x) {
  g1 <- predict(cubist_final_fit, new_data = data.frame(fza = x[1], 
                                                          fzt = x[2],
                                                          vc = x[3],
                                                          lc = "emulsion")) - (2 - 0.4381)
  
    return(g1)
}
```

Testing objective function and constraint.

```{r}
x_test <- c(0.875, 0.15, 40)
MRR(x_test)
g1(x_test)
```

Fitness function considering Objective function and penalty term regarding constraint.

```{r}
fitness <- function(x) 
{ 
  f <- MRR(x)                        
  pen <- sqrt(.Machine$double.xmax)  # penalty term
  penalty1 <- max(g1(x),0)*pen       # penalisation for 1st inequality constraint
  f - penalty1                       # fitness function value
}
```

Defining algorithims to the optimization.

```{r}
ALGOS <- c("ALO", "DA", "GWO", "MFO", "WOA")
  
#  c("ABC", "ALO", "BA", "BHO", "CLONALG", "CS", "CSO", "DA", "DE", "FFA", "GA", "GBS", "GOA", "GWO", "HS", "KH", "MFO", "PSO", "SCA", "SFL", "WOA")

# Convergiram:
# "ABC", "ALO", "DA", "DE", "GWO", "MFO", "PSO", "WOA"

# Tempo satisfatorio entre os que convergiram:
# "ALO", "DA", "GWO", "MFO", "WOA"
```

Optimization.

```{r,include = F}
result_meta <- metaOpt(fitness, optimType="MAX", numVar = 3, 
                       algorithm = ALGOS,  
                       rangeVar = matrix(c(0.50, 0.1, 20, 
                                           1.25, 0.2, 60),
                                         nrow = 2,
                                         byrow=T),
                       control = list(numPopulation = 50, maxIter = 100))
```

```{r}
result_meta
```

```{r message = F, echo = F}
############################ RESULTADOS lc = "emulsion" #########################
################# rodada 1
# $result
#          var1 var2 var3
# ALO 0.8657019  0.2   60
# DA  0.8657020  0.2   60
# GWO 0.8654987  0.2   60
# MFO 0.8657020  0.2   60
# WOA 0.8657019  0.2   60
# 
# $optimumValue
#     optimum_value
# ALO      1159.478
# DA       1159.478
# GWO      1159.206
# MFO      1159.478
# WOA      1159.478
# 
# $timeElapsed
#      user system elapsed
# ALO 59.48   1.47   60.97
# DA  59.67   1.45   61.41
# GWO 57.37   1.78   59.15
# MFO 57.48   1.45   58.89
# WOA 57.20   1.69   58.90

################# rodada 2
# $result
#          var1 var2 var3
# ALO 0.8657019  0.2   60
# DA  0.8657020  0.2   60
# GWO 0.8656948  0.2   60
# MFO 0.8657020  0.2   60
# WOA 0.8657013  0.2   60
# 
# $optimumValue
#     optimum_value
# ALO      1159.478
# DA       1159.478
# GWO      1159.469
# MFO      1159.478
# WOA      1159.478
# 
# $timeElapsed
#      user system elapsed
# ALO 57.25   1.67   58.91
# DA  58.57   1.77   60.33
# GWO 58.03   1.58   59.61
# MFO 57.00   1.45   58.49
# WOA 57.73   1.50   59.19

################# rodada 3
# $result
#          var1 var2 var3
# ALO 0.8657019  0.2   60
# DA  0.8657019  0.2   60
# GWO 0.8656480  0.2   60
# MFO 0.8657020  0.2   60
# WOA 0.8657019  0.2   60
# 
# $optimumValue
#     optimum_value
# ALO      1159.478
# DA       1159.478
# GWO      1159.406
# MFO      1159.478
# WOA      1159.478
# 
# $timeElapsed
#      user system elapsed
# ALO 57.90   1.80   59.68
# DA  58.81   1.72   60.55
# GWO 57.64   1.58   59.23
# MFO 57.19   1.92   59.11
# WOA 58.08   1.39   59.46

################# rodada 4
# $result
#          var1 var2 var3
# ALO 0.8657019  0.2   60
# DA  0.8657020  0.2   60
# GWO 0.8655567  0.2   60
# MFO 0.8657020  0.2   60
# WOA 0.8657019  0.2   60
# 
# $optimumValue
#     optimum_value
# ALO      1159.478
# DA       1159.478
# GWO      1159.284
# MFO      1159.478
# WOA      1159.478
# 
# $timeElapsed
#      user system elapsed
# ALO 58.09   1.70   59.79
# DA  58.72   1.68   60.42
# GWO 57.46   1.65   59.07
# MFO 57.26   1.92   59.15
# WOA 57.57   1.49   59.03

################# rodada 5
# $result
#          var1 var2 var3
# ALO 0.8657019  0.2   60
# DA  0.8657020  0.2   60
# GWO 0.8657013  0.2   60
# MFO 0.8657020  0.2   60
# WOA 0.8657019  0.2   60
# 
# $optimumValue
#     optimum_value
# ALO      1159.478
# DA       1159.478
# GWO      1159.477
# MFO      1159.478
# WOA      1159.478
# 
# $timeElapsed
#      user system elapsed
# ALO 57.37   2.00   59.36
# DA  58.81   1.47   60.28
# GWO 57.41   1.68   59.11
# MFO 57.31   1.72   59.04
# WOA 57.31   1.61   58.92
```

```{r message = F, echo = F}
############################ RESULTADOS lc = mql" #########################
################# rodada 1
# $result
#          var1 var2     var3
# ALO 0.8840627  0.2 56.31781
# DA  0.8841648  0.2 56.31277
# GWO 0.8326769  0.2 59.37141
# MFO 0.8834465  0.2 56.34821
# WOA 0.8702904  0.2 56.99713
# 
# $optimumValue
#     optimum_value
# ALO      1111.406
# DA       1111.435
# GWO      1103.558
# MFO      1111.231
# WOA      1107.287
# 
# $timeElapsed
#      user system elapsed
# ALO 57.92   1.24   59.20
# DA  58.24   1.80   60.06
# GWO 57.78   1.50   59.28
# MFO 56.78   1.89   58.67
# WOA 57.00   1.65   58.61

################# rodada 2
# $result
#          var1 var2     var3
# ALO 0.8841558  0.2 56.31322
# DA  0.8841642  0.2 56.31281
# GWO 0.8830263  0.2 56.35711
# MFO 0.8767414  0.2 56.67895
# WOA 0.7888814  0.2 60.00000
# 
# $optimumValue
#     optimum_value
# ALO      1111.432
# DA       1111.435
# GWO      1110.878
# MFO      1109.269
# WOA      1056.580
# 
# $timeElapsed
#      user system elapsed
# ALO 57.81   1.60   59.49
# DA  58.86   1.72   60.62
# GWO 58.04   1.75   59.87
# MFO 57.58   1.51   59.13
# WOA 57.72   1.66   59.42

################# rodada 3
# $result
#          var1 var2     var3
# ALO 0.8838091  0.2 56.33032
# DA  0.8841624  0.2 56.31289
# GWO 0.8813889  0.2 56.40551
# MFO 0.8841648  0.2 56.31278
# WOA 0.7888810  0.2 60.00000
# 
# $optimumValue
#     optimum_value
# ALO      1111.334
# DA       1111.434
# GWO      1109.770
# MFO      1111.435
# WOA      1056.580
# 
# $timeElapsed
#      user system elapsed
# ALO 58.64   1.50   60.14
# DA  58.80   1.70   60.50
# GWO 57.33   1.67   59.03
# MFO 57.76   1.39   59.22
# WOA 57.61   1.52   59.30

################# rodada 4
# $result
#          var1 var2     var3
# ALO 0.8841624  0.2 56.31289
# DA  0.8841647  0.2 56.31278
# GWO 0.8793777  0.2 56.52900
# MFO 0.8840158  0.2 56.32013
# WOA 0.8906443  0.2 52.67696
# 
# $optimumValue
#     optimum_value
# ALO      1111.434
# DA       1111.435
# GWO      1109.661
# MFO      1111.393
# WOA      1047.295
# 
# $timeElapsed
#      user system elapsed
# ALO 57.14   1.98   59.17
# DA  59.28   1.38   60.72
# GWO 57.34   1.47   58.89
# MFO 57.74   1.67   59.47
# WOA 56.80   2.00   58.86

################# rodada 5
# $result
#          var1 var2     var3
# ALO 0.8840752  0.2 56.31719
# DA  0.8757833  0.2 56.72621
# GWO 0.8828399  0.2 56.37154
# MFO 0.8841295  0.2 56.31452
# WOA 0.8304050  0.2 59.50136
# 
# $optimumValue
#     optimum_value
# ALO      1111.409
# DA       1108.980
# GWO      1110.927
# MFO      1111.425
# WOA      1102.956
# 
# $timeElapsed
#      user system elapsed
# ALO 57.44   1.81   59.25
# DA  58.84   1.75   60.57
# GWO 57.22   1.60   58.86
# MFO 57.22   1.59   58.91
# WOA 57.42   1.66   59.11

```

### Plotting MRR function

```{r}
x1_range <- c(0.5, 1.25)
x2_range <- c(0.1, 0.2)
x3_range <- c(20, 60)

x1 <- seq(x1_range[1], x1_range[2], length.out = 50)
x2 <- seq(x2_range[1], x2_range[2], length.out = 50)
x3 <- seq(x3_range[1], x3_range[2], length.out = 50)

z <- array(0, dim = c(length(x1), length(x2), length(x3)))

for (i in 1:length(x1)) {
  for (j in 1:length(x2)) {
    for (k in 1:length(x3)) {
      z[i, j, k] <- MRR(c(x1[i], x2[j], x3[k]))
    }
  }
}

library(ggpubr)
library(reshape2)
df <- melt(z)
colnames(df) <- c("x1", "x2", "x3", "z")

contour_plot <- ggplot(df, aes(x = x1, y = x2, z = z)) +
  geom_tile(aes(fill=z)) +
  scale_fill_distiller(palette = "RdBu",
                       direction = -1) +
  geom_contour(color = "black") + 
  labs(x = "fza", y = "fzt", fill = "MRR") +
  theme_bw() #+
  # ggtitle("MRR(fza, fzt)")
contour_plot2 <- ggplot(df, aes(x = x1, y = x3, z = z)) +
  geom_tile(aes(fill=z)) +
  scale_fill_distiller(palette = "RdBu",
                       direction = -1) +
  geom_contour(color = "black") + 
  labs(x = "fza", y = "vc", fill = "MRR") +
  theme_bw() #+
  # ggtitle("MRR(fza, vc)")
contour_plot3 <- ggplot(df, aes(x = x2, y = x3, z = z)) +
  geom_tile(aes(fill=z)) +
  scale_fill_distiller(palette = "RdBu",
                       direction = -1) +
  geom_contour(color = "black") + 
  labs(x = "fzt", y = "vc", fill = "MRR") +
  theme_bw() #+
  # ggtitle("MRR(fzt, vc)")

ggarrange(contour_plot,contour_plot2,contour_plot3, common.legend = TRUE, nrow = 1)
```

### plotting decision space with objective function and learned constraint

```{r}
h_x_add_err <- function(x) {
  h <- as.numeric(predict(cubist_final_fit, new_data = data.frame(fza = x[1],
                                                                  fzt = x[2],
                                                                  vc = x[3],
                                                                  lc = "emulsion"))) - 2
  return(h)
}
```

```{r}
find_x1 <- function(x3, x2) {
  lower <- 0.82
  upper <- 1
  
  while (upper - lower > 1e-6) {
    mid <- (lower + upper) / 2
    result <- g1(c(mid, x2, x3))
    
    if (result == 0) {
      return(mid)
    } else if (result < 0) {
      lower <- mid
    } else {
      upper <- mid
    }
  }
  
  return((lower + upper) / 2)
}

x3_values <- seq(20, 60, length = 200)
x2 <- 0.200
x1_values <- sapply(x3_values, find_x1, x2 = x2)

result_df <- data.frame(x1 = x1_values, x3 = x3_values)
```

```{r}
find_x1_ <- function(x3, x2) {
  # Define um intervalo inicial para x1
  lower <- 1
  upper <- 1.2
  
  while (upper - lower > 1e-6) {
    mid <- (lower + upper) / 2
    result <- h_x_add_err(c(mid, x2, x3))
    
    if (result == 0) {
      return(mid)
    } else if (result < 0) {
      lower <- mid
    } else {
      upper <- mid
    }
  }
  
  return((lower + upper) / 2)
}

x1_values2 <- sapply(x3_values, find_x1_, x2 = x2)

result_df2 <- data.frame(x1 = x1_values2, x3 = x3_values)

xys <- expand.grid(x1=x1,x3=x3)
xys <- data.frame(x1 = xys$x1,
                  x2 = 0.2,
                  x3 = xys$x3)
zs2 <- matrix(apply(xys,1,MRR), nrow = length(x1)) # previsao modelo MRR

contour(x=x1, y=x3, z=zs2, col = "royalblue3", #  "#C71585", 
        labcex = 1, method = "edge",
        xlab = "fza", ylab = "vc", lwd = 1.5)
lines(result_df, col = "red", lwd = 1.5)
lines(result_df2, col = "red", lty = 2, lwd = 1.5)
points(0.8657019, 60, pch = "*", col = "seagreen3", cex = 2)
legend(0.6, 34, legend=c("MRR"),
       col=c("royalblue3"), lty=c(1), pch = c(NA), 
       cex = .8, box.lty=0)
legend(0.55, 30, legend=c("Ra = 2 - Err_T"),
       col=c("red"), lty=c(1), pch = c(NA), 
       cex = .8, box.lty=0)
legend(0.55, 26, legend=c("Ra = 2"),
       col=c("red"), lty=c(2), pch = c(NA), 
       cex = .8, box.lty=0)
legend(0.55, 22, legend=c("max{MRR}"),
       col=c("seagreen3"), pch = c("*"), 
       cex = .8, box.lty=0)
```


```{r, message = F, include=FALSE, echo=FALSE}
# for(i in seq(10,100,by=10)){
# 
# set.seed(7)
# result_meta <- metaOpt(fitness, optimType="MAX", numVar = 3, 
#                        algorithm = ALGOS,  
#                        rangeVar = matrix(c(0.50, 0.1, 20, 
#                                            1.25, 0.2, 60),
#                                          nrow = 2,
#                                          byrow=T),
#                        control = list(numPopulation = 50, maxIter = i),
#                        )
# 
# assign(paste0("result_meta", i), (result_meta))
# 
# }
```

```{r, message = F, include=FALSE, echo=FALSE}
# optim_conv <-matrix(c(
#   result_meta10$optimumValue,
#   result_meta20$optimumValue,
#   result_meta30$optimumValue,
#   result_meta40$optimumValue,
#   result_meta50$optimumValue,
#   result_meta60$optimumValue,
#   result_meta70$optimumValue,
#   result_meta80$optimumValue,
#   result_meta90$optimumValue,
#   result_meta100$optimumValue), ncol = 5, byrow = T)
# 
# optim_conv <- data.frame(optim_conv)
# colnames(optim_conv) <- c("ALO", "DA", "GWO", "MFO", "WOA")
# 
# 
# optim_conv2 <- data.frame(MRR = c(optim_conv$ALO,
#                                   optim_conv$DA,
#                                   optim_conv$GWO,
#                                   optim_conv$MFO,
#                                   optim_conv$WOA),
#                           alg = rep(colnames(optim_conv), each = 10))
# optim_conv2$iter <- rep(seq(10,100, by = 10), 5)
# 
# ggplot(optim_conv2, aes(x = iter, y = MRR, col = alg, pch = alg)) +
#   geom_point() +
#   geom_line() +
#   labs(col = "algorithm", pch = "algorithm", x ="iteration") +
#   theme_bw()

# optim_conv2 %>%
#   filter(alg == "ALO" | alg == "DA" | alg == "MFO") %>%
# ggplot(aes(x = iter, y = MRR, col = alg, pch = alg)) +
#   geom_point() +
#   geom_line() +
#   labs(col = "algorithm", pch = "algorithm", x = "iteration") +
#   theme_bw()

```

